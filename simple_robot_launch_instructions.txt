SIMPLE REAL ROBOT LAUNCH INSTRUCTIONS - WORKING VERSION
========================================================

This is the SIMPLE working version that uses serial_motor_demo instead of complex ROS2 control.

HARDWARE REQUIREMENTS:
=====================
- Arduino connected to /dev/ttyUSB0 running ROSArduinoBridge firmware
- LD19 LiDAR connected (USB or GPIO)
- Robot powered up

STEP-BY-STEP LAUNCH PROCESS:
============================

Terminal 1 - Motor Driver (connects to Arduino):
-----------------------------------------------
cd /home/ubuntu/dev_ws
source install/setup.bash
ros2 run serial_motor_demo driver --ros-args -p serial_port:=/dev/ttyUSB0 -p baud_rate:=57600 -p encoder_cpr:=1860 -p loop_rate:=30

This starts the driver that talks directly to your Arduino via USB.

Terminal 2 - Teleop Bridge (converts cmd_vel to motor commands):
--------------------------------------------------------------
cd /home/ubuntu/dev_ws
source install/setup.bash
ros2 run serial_motor_demo teleop_bridge

This converts /cmd_vel messages to /motor_command messages for the Arduino.

Terminal 3 - LiDAR Driver:
--------------------------
cd /home/ubuntu/dev_ws
source install/setup.bash
ros2 launch ldlidar_node ldlidar_bringup.launch.py

This starts the LiDAR and publishes /scan data.

Terminal 4 - LiDAR Activation (run after Terminal 3 starts):
-----------------------------------------------------------
cd /home/ubuntu/dev_ws
source install/setup.bash
ros2 lifecycle set /ldlidar_node configure
ros2 lifecycle set /ldlidar_node activate

This activates the LiDAR to start publishing scan data.

ON YOUR DEV MACHINE:
===================

Terminal 1 (Dev) - Keyboard Teleop:
-----------------------------------
cd /home/ubuntu/dev_ws
source install/setup.bash
ros2 run teleop_twist_keyboard teleop_twist_keyboard

This publishes to /cmd_vel which the teleop_bridge converts to motor commands.

Terminal 2 (Dev) - RViz:
------------------------
cd /home/ubuntu/dev_ws
source install/setup.bash
ros2 run rviz2 rviz2

We'll configure RViz from scratch to ensure LiDAR data shows up properly.

Terminal 3 (Dev) - Robot State Publisher:
-----------------------------------------
cd /home/ubuntu/dev_ws
source install/setup.bash
ros2 launch pharma_bot rsp.launch.py use_sim_time:=false

This provides the robot model (URDF) to RViz.

Terminal 4 (Dev) - Static Transform (connects LiDAR to robot):
------------------------------------------------------------
cd /home/ubuntu/dev_ws
source install/setup.bash
ros2 run tf2_ros static_transform_publisher 0.0 0.0 0.15 0.0 0.0 0.0 base_link ldlidar_base

This tells ROS where the LiDAR is mounted on the robot.

Terminal 5 (Dev) - Joint State Publisher (makes wheels visible):
---------------------------------------------------------------
cd /home/ubuntu/dev_ws
source install/setup.bash
ros2 run joint_state_publisher joint_state_publisher --ros-args -p use_sim_time:=false

This publishes joint positions so wheels and other moving parts appear in RViz.
IMPORTANT: Run Terminal 3 (Robot State Publisher) BEFORE this command!

SIMPLE TOPIC FLOW:
==================
Dev Machine: keyboard -> /cmd_vel -> (network) -> Pi: teleop_bridge -> /motor_command -> driver -> Arduino -> motors
Pi: LiDAR -> /scan -> (network) -> Dev Machine: RViz

TESTING COMMANDS:
================
Check if topics are working:
ros2 topic list
ros2 topic echo /motor_command
ros2 topic echo /scan

Check if driver is receiving commands:
ros2 topic echo /cmd_vel

TROUBLESHOOTING:
===============
1. If no movement: Check driver connection to Arduino (/dev/ttyUSB0)
2. If no LiDAR data: Check lifecycle activation commands
3. If keyboard not working: Check teleop_bridge is running
4. If network issues: Check ROS_DOMAIN_ID on both machines

MINIMAL TEST (Just Motors):
==========================
To test just the motors without LiDAR:

Pi:
ros2 run serial_motor_demo driver --ros-args -p serial_port:=/dev/ttyUSB0
ros2 run serial_motor_demo teleop_bridge

Dev Machine:
ros2 run teleop_twist_keyboard teleop_twist_keyboard

PARAMETERS YOU CAN ADJUST:
==========================
Driver parameters:
- serial_port: /dev/ttyUSB0 (or /dev/ttyACM0)
- baud_rate: 57600
- encoder_cpr: 1860 (encoder counts per revolution)
- loop_rate: 30

Teleop bridge parameters:
- wheel_separation: 0.297 (distance between wheels)
- wheel_radius: 0.033 (wheel radius)
- max_linear_speed: 1.0
- max_angular_speed: 2.0

WHY THIS WORKS:
===============
This approach bypasses the complex ROS2 control system and uses direct serial communication:
- Driver talks directly to Arduino via USB serial
- Simple message conversion from cmd_vel to motor_command
- No controller spawning or hardware interfaces needed
- Proven working system

9. SIMPLIFIED LAUNCH (RECOMMENDED METHOD)
========================================

Instead of running 8 separate commands, use these consolidated launch files:

**On Raspberry Pi:**
```bash
export ROS_DOMAIN_ID=30
cd ~/dev_ws
source install/setup.bash
ros2 launch pharma_bot real_robot_pi.launch.py
```

This single command starts:
- Motor driver (Arduino communication)
- Teleop bridge (cmd_vel to motor conversion)  
- LiDAR driver with automatic lifecycle management

**On Dev Machine:**
```bash
export ROS_DOMAIN_ID=30
cd ~/dev_ws
source install/setup.bash
ros2 launch pharma_bot real_robot_viz.launch.py
```

This single command starts:
- Robot state publisher (URDF loading)
- Joint state publisher (wheel positions)
- Static transforms (coordinate frame linking)
- RViz2 (3D visualization)
- Teleop keyboard (in separate terminal window)

**Note**: The launch files include proper sequencing and error handling. LiDAR lifecycle commands are automatically executed after appropriate delays.

10. COORDINATE FRAME SETUP FOR BETTER VISUALIZATION
===================================================

The launch files now include a **map → odom** static transform. This creates a coordinate frame hierarchy:

```
map (fixed reference)
 └── odom (robot's starting position)
     └── base_link (robot center)
         ├── left_wheel_link
         ├── right_wheel_link  
         └── ldlidar_base (LiDAR sensor)
```

**In RViz, set Fixed Frame to "map"** for the best visualization experience:
- The environment (walls, obstacles) appears stationary
- The robot model moves through the environment
- When robot rotates, the view stays oriented to the room layout
- This matches intuitive expectation of robot navigation

This is much better than using "base_link" as fixed frame, where the robot stays centered and the world spins around it.

EXPECTED RESULTS:
================
- Robot moves when you press keys in teleop_twist_keyboard
- LiDAR data appears in RViz as red dots showing real environment
- Complete 3D robot model visible with wheels and all components
- Direct, responsive control without delays
- Robot model and LiDAR data properly aligned in RViz
- All coordinate frames (TF) connected without errors
- **Map-based perspective**: Robot moves through stationary environment when Fixed Frame is set to "map"

WHAT EACH COMPONENT DOES:
=========================
ON THE PI:
- Motor Driver: Communicates directly with Arduino via USB serial
- Teleop Bridge: Converts ROS Twist messages to motor commands
- LiDAR Driver: Reads laser scan data from LD19 sensor

ON DEV MACHINE:
- Robot State Publisher: Provides 3D robot model (URDF) to RViz
- Joint State Publisher: Makes wheels and joints visible in robot model
- Static Transforms: Connect LiDAR coordinate frame to robot base
- Teleop Keyboard: Convert keyboard input to movement commands
- RViz: Visualize robot model, LiDAR data, and coordinate frames

COORDINATE FRAME EXPLANATION:
============================
- base_link: Robot's main coordinate frame (center of robot)
- ldlidar_base/ldlidar_link: LiDAR sensor coordinate frame
- Static Transform: Tells ROS where LiDAR is mounted relative to robot
- Without static transform: Robot and LiDAR are separate, unconnected
- With static transform: Complete system with LiDAR properly positioned on robot

NETWORK TOPOLOGY:
================
Pi Hardware -> ROS Topics -> Network -> Dev Machine Visualization
Motor commands flow: Dev -> Pi
Sensor data flows: Pi -> Dev
Robot model/transforms: Dev Machine only (reduces Pi load)
